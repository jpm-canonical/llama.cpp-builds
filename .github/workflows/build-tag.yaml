name: Build llama.cpp with CUDA

on:
  release:
    types: [published]

jobs:
  build:
    permissions:
      contents: write # for uploading release assets
    
    env:
      SOURCE_TAG: ${{ github.event.release.tag_name }}
      ARTIFACT: "llamacpp-${{ matrix.jobs.name }}.tar.gz"

    strategy:
      fail-fast: false
      matrix:
        jobs:
          - name: amd64+cuda12
            runs-on: ubuntu-24.04

          # - name: arm64+cuda12
          #   runs-on: ubuntu-24.04-arm

    runs-on: ${{ matrix.jobs.runs-on }}
    steps:
      - name: Clone
        uses: actions/checkout@v5
        with:
          repository: ggml-org/llama.cpp
          ref: ${{ env.SOURCE_TAG }}

      - name: Dependencies
        run: |
          sudo apt-get -q update

          if apt-cache policy  nvidia-cuda-toolkit | grep "Candidate: 12."; then
            echo "Installing CUDA 12 packages"
          else
            echo "CUDA 12 packages not found in apt cache!"
            exit 1
          fi
          
          sudo apt-get install -q build-essential nvidia-cuda-toolkit

      - name: Build
        run: |
          cmake -B build -D LLAMA_CURL=OFF -D GGML_NATIVE=OFF -D GGML_CUDA=ON -D CMAKE_CUDA_ARCHITECTURES=all-major
          cmake --build build --config Release -j $(nproc)

      - name: Pack artifacts
        run: |
          # Prepare archive directory:
          # - bin for executables
          # - lib for shared libraries
          # - licenses directory

          mkdir -p archive/lib
          mv build/bin/*.so archive/lib/
          mv build/bin archive/
          cp -r licenses archive/
          cp LICENSE archive/licenses/

          find /usr -iname "libcudart.so.*" -exec cp -v {} archive/lib/ \;
          find /usr -iname "libcublas.so.*" -exec cp -v {} archive/lib/ \;

          tar -C archive -zcvf $ARTIFACT .

      - name: Upload artifact to release
        uses: softprops/action-gh-release@v2
        with:
          files: ${{ env.ARTIFACT }}
