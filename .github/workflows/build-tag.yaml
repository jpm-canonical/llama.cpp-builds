name: Build

on:
  release:
    types: [published]

jobs:
  build:
    permissions:
      contents: write # for uploading release assets
    
    env:
      SOURCE_TAG: ${{ github.event.release.tag_name }}
      ARTIFACT: "llamacpp-${{ matrix.jobs.name }}.tar.gz"

    strategy:
      fail-fast: false
      matrix:
        jobs:
          - name: amd64v1
            runs-on: ubuntu-24.04
            additional-cmake-flags: "-D GGML_SSE42=OFF -D GGML_AVX=OFF -D GGML_AVX_VNNI=OFF -D GGML_AVX2=OFF -D GGML_BMI2=OFF -D GGML_AVX512=OFF -D GGML_AVX512_VBMI=OFF -D GGML_AVX512_VNNI=OFF -D GGML_AVX512_BF16=OFF -D GGML_FMA=OFF -D GGML_F16C=OFF -D GGML_AMX_TILE=OFF -D GGML_AMX_INT8=OFF -D GGML_AMX_BF16=OFF"

          - name: amd64v2
            runs-on: ubuntu-24.04
            additional-cmake-flags: "-D GGML_SSE42=ON  -D GGML_AVX=OFF -D GGML_AVX_VNNI=OFF -D GGML_AVX2=OFF -D GGML_BMI2=OFF -D GGML_AVX512=OFF -D GGML_AVX512_VBMI=OFF -D GGML_AVX512_VNNI=OFF -D GGML_AVX512_BF16=OFF -D GGML_FMA=OFF -D GGML_F16C=OFF -D GGML_AMX_TILE=OFF -D GGML_AMX_INT8=OFF -D GGML_AMX_BF16=OFF"

          - name: amd64v3
            runs-on: ubuntu-24.04
            additional-cmake-flags: "-D GGML_SSE42=ON  -D GGML_AVX=ON  -D GGML_AVX_VNNI=OFF -D GGML_AVX2=ON  -D GGML_BMI2=ON  -D GGML_AVX512=OFF -D GGML_AVX512_VBMI=OFF -D GGML_AVX512_VNNI=OFF -D GGML_AVX512_BF16=OFF -D GGML_FMA=ON  -D GGML_F16C=ON  -D GGML_AMX_TILE=OFF -D GGML_AMX_INT8=OFF -D GGML_AMX_BF16=OFF"

          - name: amd64v4
            runs-on: ubuntu-24.04
            additional-cmake-flags: "-D GGML_SSE42=ON  -D GGML_AVX=ON  -D GGML_AVX_VNNI=OFF -D GGML_AVX2=ON  -D GGML_BMI2=ON  -D GGML_AVX512=ON  -D GGML_AVX512_VBMI=OFF -D GGML_AVX512_VNNI=OFF -D GGML_AVX512_BF16=OFF -D GGML_FMA=ON  -D GGML_F16C=ON  -D GGML_AMX_TILE=OFF -D GGML_AMX_INT8=OFF -D GGML_AMX_BF16=OFF"
          
          - name: arm64
            runs-on: ubuntu-24.04-arm
            # additional-cmake-flags: ""

          #
          # Builds with CUDA backend
          #
          - name: amd64+cuda12
            runs-on: ubuntu-24.04
            additional-cmake-flags: "-D GGML_CUDA=ON -D CMAKE_CUDA_ARCHITECTURES=all-major"
            cuda-toolkit: true

          - name: arm64+cuda12
            runs-on: ubuntu-24.04-arm
            additional-cmake-flags: "-D GGML_CUDA=ON -D CMAKE_CUDA_ARCHITECTURES=all-major"
            cuda-toolkit: true

    runs-on: ${{ matrix.jobs.runs-on }}
    steps:
      - name: Clone llama.cpp
        uses: actions/checkout@v5
        with:
          repository: ggml-org/llama.cpp
          ref: ${{ env.SOURCE_TAG }}

      - name: Install dependencies
        run: |
          # Install CUDA toolkit if required
          if [ "${{ matrix.jobs.cuda-toolkit }}" = "true" ]; then
            case "$(dpkg --print-architecture)" in
              amd64)
                wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2404/x86_64/cuda-keyring_1.1-1_all.deb
                ;;
              arm64)
                wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2404/sbsa/cuda-keyring_1.1-1_all.deb
                ;;
              *)
                echo "Unsupported architecture for CUDA Toolkit installation"
                exit 1
              ;;
            esac
          
            sudo dpkg -i cuda-keyring_1.1-1_all.deb
            sudo apt-get -qq update
            sudo apt-get -qq install cuda-toolkit-12-9
          else
            sudo apt-get -qq update
          fi
          
          sudo apt-get -qq install build-essential

      - name: Build
        run: |
          # Set CUDA compiler for CUDA builds
          export CUDACXX=/usr/local/cuda/bin/nvcc
          
          # Configure and build llama.cpp
          common_flags="-D LLAMA_CURL=OFF -D GGML_NATIVE=OFF"
          artifacts_flags="-D LLAMA_BUILD_TESTS=OFF -D LLAMA_BUILD_EXAMPLES=OFF -D LLAMA_BUILD_TOOLS=ON -D LLAMA_BUILD_SERVER=ON"
          cmake -B build -D $common_flags $artifacts_flags ${{ matrix.jobs.additional-cmake-flags }}
          cmake --build build --config Release -j $(nproc)

      - name: Pack artifacts
        run: |
          # Prepare archive directory:
          # - bin for executables
          # - lib for shared libraries
          # - licenses directory
          mkdir -p archive/lib
          mv build/bin/*.so* archive/lib/
          mv build/bin archive/
          cp -r licenses archive/
          cp LICENSE archive/licenses/
          
          # Copy CUDA runtime libraries if built with CUDA
          if [ "${{ matrix.jobs.cuda-toolkit }}" = "true" ]; then
            copy="cp --no-dereference -v {} archive/lib/ "
            find /usr -name "libcudart.so.*" -exec $copy \;
            find /usr -name "libcublas.so.*" -exec $copy \;
            find /usr -name "libcublasLt.so.*" -exec $copy \;
          fi

          tar -C archive -zcvf $ARTIFACT .

      - name: Upload artifact to release
        uses: softprops/action-gh-release@v2
        with:
          files: ${{ env.ARTIFACT }}
