name: Build

on:
  release:
    types: [created]

jobs:
  build:
    permissions:
      contents: write # for uploading release assets
    
    env:
      COMMON_CMAKE_FLAGS: "-D BUILD_SHARED_LIBS=OFF -D LLAMA_CURL=OFF -D GGML_NATIVE=OFF"

    strategy:
      fail-fast: false
      matrix:
        jobs:
          - name: amd64-avx-sse4
            runs-on: ubuntu-24.04
            additional-cmake-flags: "-D GGML_F16C=OFF -D GGML_FMA=OFF -D GGML_BMI2=OFF -D GGML_AVX2=OFF"

          - name: amd64-avx2
            runs-on: ubuntu-24.04
            # additional-cmake-flags: ""

          - name: amd64-avx512
            runs-on: ubuntu-24.04
            additional-cmake-flags: "-DGGML_AVX512=ON"

          - name: amd64-cuda
            runs-on: ubuntu-24.04
            additional-cmake-flags: "-D GGML_CUDA=ON -D CMAKE_CUDA_ARCHITECTURES=all-major"
            apt-dependencies: "nvidia-cuda-toolkit"

          - name: arm-neon
            runs-on: ubuntu-24.04-arm
            # additional-cmake-flags: ""

    runs-on: ${{ matrix.jobs.runs-on }}
    steps:
      - name: Clone
        uses: actions/checkout@v5
        with:
          repository: ggml-org/llama.cpp
          ref: ${{ github.event.release.tag_name }}
          fetch-depth: 1

      - name: Dependencies
        run: |
          sudo apt-get update
          sudo apt-get install build-essential ${{ matrix.jobs.apt-dependencies }}

      - name: Build
        run: |
          cmake -B build ${{ env.COMMON_CMAKE_FLAGS }} ${{ matrix.jobs.additional-cmake-flags }}
          cmake --build build --config Release -j $(nproc)

      - name: Pack artifacts
        run: |
          cp LICENSE ./build/bin/
          zip -r llamacpp-${{ github.event.release.tag_name }}-${{ matrix.jobs.name }}.zip ./build/bin/*

      - name: Upload artifact to release
        uses: softprops/action-gh-release@v2
        with:
          files: llamacpp-${{ github.event.release.tag_name }}-${{ matrix.jobs.name }}.zip
